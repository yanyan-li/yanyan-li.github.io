---
layout: post
title: "Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification"
# categories: junk
author:
- Yan Li 
- Yingzhao Li
- Gim Hee Lee
meta: "Springfield"
---
<div style="float:left;margin:0 10px 10px 0" class="col-md-4" markdown="1">
  <!-- ![Alt Text](../img/folder/blah.jpg) -->
  <img width="300px" class="center-block" src="../../../images/ReimanLine.gif">
  </div>
<li> <b>Yan Li</b>, Yingzhao Li, Gim Hee Lee. <span style="color:#B31B1B;font-weight:bold;">@ AAAI 2026 (Oral)</span> </li>
<li>
<span class="link"><a target=_blank href="https://yanyan-li.github.io/project/vlx/active3d.html">[Project Page]</a></span>
</li>
<div style="clear: both;"></div>

<h3>Abstract:</h3>
<div>
We present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. 
We introduce a hybrid implicitâ€“explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. 
Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. 
To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. 
The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. 
</div>